{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# hide\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# hide\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# export\\nimport math\\nimport os\\nimport time\\nimport logging\\nfrom pathlib import Path\\nfrom typing import Collection\\n\\nimport prefect\\nimport fastparquet\\nimport spell.metrics\\nfrom prefect import task, Flow\\nfrom prefect.engine.signals import SKIP\\nfrom prefect.tasks.shell import ShellTask\\n\\nfrom neuralmusic.midi import parse_midi_file\\n\\nlog = logging.getLogger(\\\"data.etl\\\")\";\n",
       "                var nbb_formatted_code = \"# export\\nimport math\\nimport os\\nimport time\\nimport logging\\nfrom pathlib import Path\\nfrom typing import Collection\\n\\nimport prefect\\nimport fastparquet\\nimport spell.metrics\\nfrom prefect import task, Flow\\nfrom prefect.engine.signals import SKIP\\nfrom prefect.tasks.shell import ShellTask\\n\\nfrom neuralmusic.midi import parse_midi_file\\n\\nlog = logging.getLogger(\\\"data.etl\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Collection\n",
    "\n",
    "import prefect\n",
    "import fastparquet\n",
    "import spell.metrics\n",
    "from prefect import task, Flow\n",
    "from prefect.engine.signals import SKIP\n",
    "from prefect.tasks.shell import ShellTask\n",
    "\n",
    "from neuralmusic.midi import parse_midi_file\n",
    "\n",
    "log = logging.getLogger(\"data.etl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# default_exp data.etl\\n# default_cls_lvl 3\";\n",
       "                var nbb_formatted_code = \"# default_exp data.etl\\n# default_cls_lvl 3\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default_exp data.etl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL to process MIDI files\n",
    "\n",
    "> Turning a bunch of MIDI files into parquet data\n",
    "\n",
    "This ETL takes a tar.gz'd file full of arbitrary midi files and outputs a bunch of parquet files containing neat dataframes with pitch, durations and velocity triplets for each song.\n",
    "\n",
    "First we need some global variables and reporting tools to log the progress. This ETL may run locally or on Spell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# export\\ntotal_songs = 0\\nmalformed_songs = 0\\nvalid_songs = 0\\nvalid_notes = 0\\n\\nstarted_at = None\\n\\n\\ndef init_stats():\\n    \\\"\\\"\\\"\\n    Resets reporting stats to zero.\\n    \\\"\\\"\\\"\\n    global total_songs\\n    global valid_songs\\n    global valid_notes\\n    global malformed_songs\\n    global started_at\\n\\n    total_songs = 0\\n    malformed_songs = 0\\n    valid_songs = 0\\n    valid_notes = 0\\n\\n    started_at = time.time()\\n\\n\\nif \\\"SPELL\\\" in os.environ:\\n    metric = spell.metrics.send_metric\\n\\n    def metric(_logger, k, v):\\n        spell.metrics.send_metric(k, v)\\n\\n\\nelse:\\n\\n    def metric(logger, k, v):\\n        logger.info(f\\\"[{k}]: {v}\\\")\\n\\n\\ndef report(logger):\\n    \\\"\\\"\\\"\\n    Reports current metrics, either to Spell or to a logger.\\n    \\\"\\\"\\\"\\n    elapsed = time.time() - started_at\\n    metric(logger, \\\"Total Songs\\\", total_songs)\\n    metric(logger, \\\"Malformed Songs\\\", malformed_songs)\\n    metric(logger, \\\"Notes\\\", valid_notes)\\n    metric(logger, \\\"Total Songs / second\\\", (total_songs / elapsed))\\n    metric(logger, \\\"Notes / second\\\", (valid_notes / elapsed))\";\n",
       "                var nbb_formatted_code = \"# export\\ntotal_songs = 0\\nmalformed_songs = 0\\nvalid_songs = 0\\nvalid_notes = 0\\n\\nstarted_at = None\\n\\n\\ndef init_stats():\\n    \\\"\\\"\\\"\\n    Resets reporting stats to zero.\\n    \\\"\\\"\\\"\\n    global total_songs\\n    global valid_songs\\n    global valid_notes\\n    global malformed_songs\\n    global started_at\\n\\n    total_songs = 0\\n    malformed_songs = 0\\n    valid_songs = 0\\n    valid_notes = 0\\n\\n    started_at = time.time()\\n\\n\\nif \\\"SPELL\\\" in os.environ:\\n    metric = spell.metrics.send_metric\\n\\n    def metric(_logger, k, v):\\n        spell.metrics.send_metric(k, v)\\n\\n\\nelse:\\n\\n    def metric(logger, k, v):\\n        logger.info(f\\\"[{k}]: {v}\\\")\\n\\n\\ndef report(logger):\\n    \\\"\\\"\\\"\\n    Reports current metrics, either to Spell or to a logger.\\n    \\\"\\\"\\\"\\n    elapsed = time.time() - started_at\\n    metric(logger, \\\"Total Songs\\\", total_songs)\\n    metric(logger, \\\"Malformed Songs\\\", malformed_songs)\\n    metric(logger, \\\"Notes\\\", valid_notes)\\n    metric(logger, \\\"Total Songs / second\\\", (total_songs / elapsed))\\n    metric(logger, \\\"Notes / second\\\", (valid_notes / elapsed))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "total_songs = 0\n",
    "malformed_songs = 0\n",
    "valid_songs = 0\n",
    "valid_notes = 0\n",
    "\n",
    "started_at = None\n",
    "\n",
    "\n",
    "def init_stats():\n",
    "    \"\"\"\n",
    "    Resets reporting stats to zero.\n",
    "    \"\"\"\n",
    "    global total_songs\n",
    "    global valid_songs\n",
    "    global valid_notes\n",
    "    global malformed_songs\n",
    "    global started_at\n",
    "\n",
    "    total_songs = 0\n",
    "    malformed_songs = 0\n",
    "    valid_songs = 0\n",
    "    valid_notes = 0\n",
    "\n",
    "    started_at = time.time()\n",
    "\n",
    "\n",
    "if \"SPELL\" in os.environ:\n",
    "    metric = spell.metrics.send_metric\n",
    "\n",
    "    def metric(_logger, k, v):\n",
    "        spell.metrics.send_metric(k, v)\n",
    "\n",
    "\n",
    "else:\n",
    "\n",
    "    def metric(logger, k, v):\n",
    "        logger.info(f\"[{k}]: {v}\")\n",
    "\n",
    "\n",
    "def report(logger):\n",
    "    \"\"\"\n",
    "    Reports current metrics, either to Spell or to a logger.\n",
    "    \"\"\"\n",
    "    elapsed = time.time() - started_at\n",
    "    metric(logger, \"Total Songs\", total_songs)\n",
    "    metric(logger, \"Malformed Songs\", malformed_songs)\n",
    "    metric(logger, \"Notes\", valid_notes)\n",
    "    metric(logger, \"Total Songs / second\", (total_songs / elapsed))\n",
    "    metric(logger, \"Notes / second\", (valid_notes / elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untar'ing the file\n",
    "\n",
    "The first step is to untar the file containing the MIDI files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# export\\n@task\\ndef untar_cmd(file_path: str, outdir: str) -> str:\\n    \\\"\\\"\\\"\\n    Untars a .tar.gz file onto a directory (will create it if it does not exist).\\n    \\\"\\\"\\\"\\n    if os.path.exists(outdir):\\n        raise SKIP(\\\"Output directory already exists.\\\")\\n    return f\\\"mkdir -p {outdir} && tar -zxf {file_path} -C {outdir}\\\"\\n\\n\\nuntar = ShellTask(name=\\\"untar_task\\\")\";\n",
       "                var nbb_formatted_code = \"# export\\n@task\\ndef untar_cmd(file_path: str, outdir: str) -> str:\\n    \\\"\\\"\\\"\\n    Untars a .tar.gz file onto a directory (will create it if it does not exist).\\n    \\\"\\\"\\\"\\n    if os.path.exists(outdir):\\n        raise SKIP(\\\"Output directory already exists.\\\")\\n    return f\\\"mkdir -p {outdir} && tar -zxf {file_path} -C {outdir}\\\"\\n\\n\\nuntar = ShellTask(name=\\\"untar_task\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@task\n",
    "def untar_cmd(file_path: str, outdir: str) -> str:\n",
    "    \"\"\"\n",
    "    Untars a .tar.gz file onto a directory (will create it if it does not exist).\n",
    "    \"\"\"\n",
    "    if os.path.exists(outdir):\n",
    "        raise SKIP(\"Output directory already exists.\")\n",
    "    return f\"mkdir -p {outdir} && tar -zxf {file_path} -C {outdir}\"\n",
    "\n",
    "\n",
    "untar = ShellTask(name=\"untar_task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning the files in minibatches\n",
    "\n",
    "Since the tar.gz file may contain a huge amount of MIDI files, we'll partition those files into minibatches that we can process in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# export\\n@task(skip_on_upstream_skip=False)\\ndef partition_files(\\n    data_path: str, partition_size: int = 100, min_partitions: int = 4\\n) -> list:\\n    \\\"\\\"\\\"\\n    Partitions the midi files in data_path into chunks.\\n    \\\"\\\"\\\"\\n    midi_files = list(Path(data_path).glob(\\\"**/*.mid\\\"))\\n    n = len(midi_files)\\n    if (n / partition_size) < min_partitions:\\n        partition_size = math.ceil(n / min_partitions)\\n    logger = prefect.context.get(\\\"logger\\\")\\n    logger.info(\\n        f\\\"Processing {n} MIDI files partitioned into groups of {partition_size}\\\"\\n    )\\n    return [\\n        midi_files[i : i + partition_size]\\n        for i in range(0, len(midi_files), partition_size)\\n    ]\";\n",
       "                var nbb_formatted_code = \"# export\\n@task(skip_on_upstream_skip=False)\\ndef partition_files(\\n    data_path: str, partition_size: int = 100, min_partitions: int = 4\\n) -> list:\\n    \\\"\\\"\\\"\\n    Partitions the midi files in data_path into chunks.\\n    \\\"\\\"\\\"\\n    midi_files = list(Path(data_path).glob(\\\"**/*.mid\\\"))\\n    n = len(midi_files)\\n    if (n / partition_size) < min_partitions:\\n        partition_size = math.ceil(n / min_partitions)\\n    logger = prefect.context.get(\\\"logger\\\")\\n    logger.info(\\n        f\\\"Processing {n} MIDI files partitioned into groups of {partition_size}\\\"\\n    )\\n    return [\\n        midi_files[i : i + partition_size]\\n        for i in range(0, len(midi_files), partition_size)\\n    ]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@task(skip_on_upstream_skip=False)\n",
    "def partition_files(\n",
    "    data_path: str, partition_size: int = 100, min_partitions: int = 4\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Partitions the midi files in data_path into chunks.\n",
    "    \"\"\"\n",
    "    midi_files = list(Path(data_path).glob(\"**/*.mid\"))\n",
    "    n = len(midi_files)\n",
    "    if (n / partition_size) < min_partitions:\n",
    "        partition_size = math.ceil(n / min_partitions)\n",
    "    logger = prefect.context.get(\"logger\")\n",
    "    logger.info(\n",
    "        f\"Processing {n} MIDI files partitioned into groups of {partition_size}\"\n",
    "    )\n",
    "    return [\n",
    "        midi_files[i : i + partition_size]\n",
    "        for i in range(0, len(midi_files), partition_size)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing a minibatch\n",
    "\n",
    "For each minibatch, we'll go through its MIDI files, parse them, and write them to a separate Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# export\\n@task\\ndef process_and_write(mini_batch: Collection[str], outdir: str) -> bytes:\\n    \\\"\\\"\\\"\\n    Parses a mini batch of MIDI files and writes the results to a parquet file.\\n    The filename is determined by `map_index`. Returns the amount of notes it parsed.\\n    \\\"\\\"\\\"\\n    frame_no = prefect.context.get(\\\"map_index\\\")\\n    Path(outdir).mkdir(parents=True, exist_ok=True)\\n    outfile = f\\\"{outdir}/out_{frame_no}.parq\\\"\\n\\n    logger = prefect.context.get(\\\"logger\\\")\\n\\n    should_append = False\\n\\n    global total_songs\\n    global valid_songs\\n    global valid_notes\\n    global malformed_songs\\n\\n    for file in mini_batch:\\n        df, processed_notes = parse_midi_file(file)\\n        if df is not None:\\n            valid_songs += 1\\n            valid_notes += processed_notes\\n\\n            fastparquet.write(outfile, df, compression=\\\"SNAPPY\\\", append=should_append)\\n            del df\\n            should_append = True\\n        else:\\n            malformed_songs += 1\\n            logger.warning(f\\\"[Minibatch {frame_no}] {file} could not be processed.\\\")\\n\\n        total_songs += 1\\n        report(logger)\\n\\n    return outfile\";\n",
       "                var nbb_formatted_code = \"# export\\n@task\\ndef process_and_write(mini_batch: Collection[str], outdir: str) -> bytes:\\n    \\\"\\\"\\\"\\n    Parses a mini batch of MIDI files and writes the results to a parquet file.\\n    The filename is determined by `map_index`. Returns the amount of notes it parsed.\\n    \\\"\\\"\\\"\\n    frame_no = prefect.context.get(\\\"map_index\\\")\\n    Path(outdir).mkdir(parents=True, exist_ok=True)\\n    outfile = f\\\"{outdir}/out_{frame_no}.parq\\\"\\n\\n    logger = prefect.context.get(\\\"logger\\\")\\n\\n    should_append = False\\n\\n    global total_songs\\n    global valid_songs\\n    global valid_notes\\n    global malformed_songs\\n\\n    for file in mini_batch:\\n        df, processed_notes = parse_midi_file(file)\\n        if df is not None:\\n            valid_songs += 1\\n            valid_notes += processed_notes\\n\\n            fastparquet.write(outfile, df, compression=\\\"SNAPPY\\\", append=should_append)\\n            del df\\n            should_append = True\\n        else:\\n            malformed_songs += 1\\n            logger.warning(f\\\"[Minibatch {frame_no}] {file} could not be processed.\\\")\\n\\n        total_songs += 1\\n        report(logger)\\n\\n    return outfile\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@task\n",
    "def process_and_write(mini_batch: Collection[str], outdir: str) -> bytes:\n",
    "    \"\"\"\n",
    "    Parses a mini batch of MIDI files and writes the results to a parquet file.\n",
    "    The filename is determined by `map_index`. Returns the amount of notes it parsed.\n",
    "    \"\"\"\n",
    "    frame_no = prefect.context.get(\"map_index\")\n",
    "    Path(outdir).mkdir(parents=True, exist_ok=True)\n",
    "    outfile = f\"{outdir}/out_{frame_no}.parq\"\n",
    "\n",
    "    logger = prefect.context.get(\"logger\")\n",
    "\n",
    "    should_append = False\n",
    "\n",
    "    global total_songs\n",
    "    global valid_songs\n",
    "    global valid_notes\n",
    "    global malformed_songs\n",
    "\n",
    "    for file in mini_batch:\n",
    "        df, processed_notes = parse_midi_file(file)\n",
    "        if df is not None:\n",
    "            valid_songs += 1\n",
    "            valid_notes += processed_notes\n",
    "\n",
    "            fastparquet.write(outfile, df, compression=\"SNAPPY\", append=should_append)\n",
    "            del df\n",
    "            should_append = True\n",
    "        else:\n",
    "            malformed_songs += 1\n",
    "            logger.warning(f\"[Minibatch {frame_no}] {file} could not be processed.\")\n",
    "\n",
    "        total_songs += 1\n",
    "        report(logger)\n",
    "\n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the parquet files\n",
    "\n",
    "Once we have all the minibatches in separate parquet files, merging them into a single dataset is trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# export\\n@task\\ndef combine_parquet_files(files: Collection[str]) -> None:\\n    \\\"\\\"\\\"\\n    Combines N parquet files with the same schema into another one.\\n    \\\"\\\"\\\"\\n    fastparquet.writer.merge(files)\";\n",
       "                var nbb_formatted_code = \"# export\\n@task\\ndef combine_parquet_files(files: Collection[str]) -> None:\\n    \\\"\\\"\\\"\\n    Combines N parquet files with the same schema into another one.\\n    \\\"\\\"\\\"\\n    fastparquet.writer.merge(files)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@task\n",
    "def combine_parquet_files(files: Collection[str]) -> None:\n",
    "    \"\"\"\n",
    "    Combines N parquet files with the same schema into another one.\n",
    "    \"\"\"\n",
    "    fastparquet.writer.merge(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together\n",
    "\n",
    "Now we can build the ETL flow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# export\\n\\n\\ndef build_etl(cfg):\\n    \\\"\\\"\\\"\\n    Builds the ETL flow.\\n    \\\"\\\"\\\"\\n    tar_gz_path = cfg.tar_gz_path\\n    outdir = cfg.outdir\\n    assert tar_gz_path, \\\"Config not found: data.etl.tar_gz_path\\\"\\n    assert outdir, \\\"Config not found: data.etl.outdir\\\"\\n\\n    with Flow(\\\"Neuralmusic Data ETL\\\") as flow:\\n        tar_gz_path = Path(cfg.tar_gz_path).resolve()\\n        assert tar_gz_path.exists(), f\\\"{tar_gz_path} does not exist\\\"\\n        command = untar_cmd(str(tar_gz_path), \\\"data\\\")\\n        untarred = untar(command=command)\\n\\n        mini_batches = partition_files(\\n            \\\"data\\\", partition_size=cfg.partition_size, upstream_tasks=[untarred]\\n        )\\n\\n        partitions = process_and_write.map(mini_batches, outdir=outdir)\\n\\n        combine_parquet_files(partitions)\\n\\n    return flow\";\n",
       "                var nbb_formatted_code = \"# export\\n\\n\\ndef build_etl(cfg):\\n    \\\"\\\"\\\"\\n    Builds the ETL flow.\\n    \\\"\\\"\\\"\\n    tar_gz_path = cfg.tar_gz_path\\n    outdir = cfg.outdir\\n    assert tar_gz_path, \\\"Config not found: data.etl.tar_gz_path\\\"\\n    assert outdir, \\\"Config not found: data.etl.outdir\\\"\\n\\n    with Flow(\\\"Neuralmusic Data ETL\\\") as flow:\\n        tar_gz_path = Path(cfg.tar_gz_path).resolve()\\n        assert tar_gz_path.exists(), f\\\"{tar_gz_path} does not exist\\\"\\n        command = untar_cmd(str(tar_gz_path), \\\"data\\\")\\n        untarred = untar(command=command)\\n\\n        mini_batches = partition_files(\\n            \\\"data\\\", partition_size=cfg.partition_size, upstream_tasks=[untarred]\\n        )\\n\\n        partitions = process_and_write.map(mini_batches, outdir=outdir)\\n\\n        combine_parquet_files(partitions)\\n\\n    return flow\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def build_etl(cfg):\n",
    "    \"\"\"\n",
    "    Builds the ETL flow.\n",
    "    \"\"\"\n",
    "    tar_gz_path = cfg.tar_gz_path\n",
    "    outdir = cfg.outdir\n",
    "    assert tar_gz_path, \"Config not found: data.etl.tar_gz_path\"\n",
    "    assert outdir, \"Config not found: data.etl.outdir\"\n",
    "\n",
    "    with Flow(\"Neuralmusic Data ETL\") as flow:\n",
    "        tar_gz_path = Path(cfg.tar_gz_path).resolve()\n",
    "        assert tar_gz_path.exists(), f\"{tar_gz_path} does not exist\"\n",
    "        command = untar_cmd(str(tar_gz_path), \"data\")\n",
    "        untarred = untar(command=command)\n",
    "\n",
    "        mini_batches = partition_files(\n",
    "            \"data\", partition_size=cfg.partition_size, upstream_tasks=[untarred]\n",
    "        )\n",
    "\n",
    "        partitions = process_and_write.map(mini_batches, outdir=outdir)\n",
    "\n",
    "        combine_parquet_files(partitions)\n",
    "\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-08 08:38:06,421] INFO - prefect.FlowRunner | Beginning Flow run for 'Neuralmusic Data ETL'\n",
      "[2019-12-08 08:38:06,425] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2019-12-08 08:38:06,439] INFO - prefect.TaskRunner | Task 'untar_cmd': Starting task run...\n",
      "[2019-12-08 08:38:06,443] INFO - prefect.TaskRunner | Task 'untar_cmd': finished task run for task with final state: 'Skipped'\n",
      "[2019-12-08 08:38:06,458] INFO - prefect.TaskRunner | Task 'untar_task': Starting task run...\n",
      "[2019-12-08 08:38:06,468] INFO - prefect.TaskRunner | Task 'untar_task': finished task run for task with final state: 'Skipped'\n",
      "[2019-12-08 08:38:06,483] INFO - prefect.TaskRunner | Task 'partition_files': Starting task run...\n",
      "[2019-12-08 08:38:06,487] INFO - prefect.Task: partition_files | Processing 3 MIDI files partitioned into groups of 1\n",
      "[2019-12-08 08:38:06,494] INFO - prefect.TaskRunner | Task 'partition_files': finished task run for task with final state: 'Success'\n",
      "[2019-12-08 08:38:06,507] INFO - prefect.TaskRunner | Task 'process_and_write': Starting task run...\n",
      "[2019-12-08 08:38:06,518] INFO - prefect.TaskRunner | Task 'process_and_write[0]': Starting task run...\n",
      "[2019-12-08 08:38:07,334] INFO - prefect.Task: process_and_write | [Total Songs]: 1\n",
      "[2019-12-08 08:38:07,335] INFO - prefect.Task: process_and_write | [Malformed Songs]: 0\n",
      "[2019-12-08 08:38:07,336] INFO - prefect.Task: process_and_write | [Notes]: 350\n",
      "[2019-12-08 08:38:07,336] INFO - prefect.Task: process_and_write | [Total Songs / second]: 1.0923736282510996\n",
      "[2019-12-08 08:38:07,337] INFO - prefect.Task: process_and_write | [Notes / second]: 382.33076988788486\n",
      "[2019-12-08 08:38:07,345] INFO - prefect.TaskRunner | Task 'process_and_write[0]': finished task run for task with final state: 'Success'\n",
      "[2019-12-08 08:38:07,357] INFO - prefect.TaskRunner | Task 'process_and_write[1]': Starting task run...\n",
      "[2019-12-08 08:38:07,685] INFO - prefect.Task: process_and_write | [Total Songs]: 2\n",
      "[2019-12-08 08:38:07,685] INFO - prefect.Task: process_and_write | [Malformed Songs]: 0\n",
      "[2019-12-08 08:38:07,686] INFO - prefect.Task: process_and_write | [Notes]: 1162\n",
      "[2019-12-08 08:38:07,687] INFO - prefect.Task: process_and_write | [Total Songs / second]: 1.5799710058287815\n",
      "[2019-12-08 08:38:07,687] INFO - prefect.Task: process_and_write | [Notes / second]: 917.963154386522\n",
      "[2019-12-08 08:38:07,695] INFO - prefect.TaskRunner | Task 'process_and_write[1]': finished task run for task with final state: 'Success'\n",
      "[2019-12-08 08:38:07,704] INFO - prefect.TaskRunner | Task 'process_and_write[2]': Starting task run...\n",
      "[2019-12-08 08:38:07,783] INFO - prefect.Task: process_and_write | [Total Songs]: 3\n",
      "[2019-12-08 08:38:07,783] INFO - prefect.Task: process_and_write | [Malformed Songs]: 0\n",
      "[2019-12-08 08:38:07,784] INFO - prefect.Task: process_and_write | [Notes]: 1457\n",
      "[2019-12-08 08:38:07,784] INFO - prefect.Task: process_and_write | [Total Songs / second]: 2.199831327019985\n",
      "[2019-12-08 08:38:07,785] INFO - prefect.Task: process_and_write | [Notes / second]: 1068.384747822706\n",
      "[2019-12-08 08:38:07,793] INFO - prefect.TaskRunner | Task 'process_and_write[2]': finished task run for task with final state: 'Success'\n",
      "[2019-12-08 08:38:07,800] INFO - prefect.TaskRunner | Task 'process_and_write': finished task run for task with final state: 'Mapped'\n",
      "[2019-12-08 08:38:07,811] INFO - prefect.TaskRunner | Task 'combine_parquet_files': Starting task run...\n",
      "[2019-12-08 08:38:07,821] INFO - prefect.TaskRunner | Task 'combine_parquet_files': finished task run for task with final state: 'Success'\n",
      "[2019-12-08 08:38:07,825] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# test\\nfrom test import test_eq, path\\nfrom omegaconf import OmegaConf\\nimport fastparquet\\n\\ntmp_path = \\\"/tmp/neuralmusic_etl\\\"\\n\\ntargz_path = path(\\\"data/midi.tar.gz\\\")\\n\\ndot_list = [f\\\"tar_gz_path={targz_path}\\\", f\\\"outdir={tmp_path}\\\", \\\"partition_size=1\\\"]\\netl_cfg = OmegaConf.from_dotlist(dot_list)\\nflow = build_etl(etl_cfg)\\n\\ninit_stats()\\n\\nstarted_at = time.time()\\nflow.run()\\n\\ntest_eq(3, total_songs)\\ntest_eq(0, malformed_songs)\\ntest_eq(3, valid_songs)\\ntest_eq(1457, valid_notes)\\n\\ndf = fastparquet.ParquetFile(tmp_path, verify=True).to_pandas()\\npitches, durations, velocities = df.values[0]\\n\\ntest_eq([\\\"7.11.2\\\", \\\"7\\\", \\\"7\\\"], pitches[0:3])\\ntest_eq([1.75, 0.5, 0.5], durations[0:3])\\ntest_eq([110, 110, 110], velocities[0:3])\";\n",
       "                var nbb_formatted_code = \"# test\\nfrom test import test_eq, path\\nfrom omegaconf import OmegaConf\\nimport fastparquet\\n\\ntmp_path = \\\"/tmp/neuralmusic_etl\\\"\\n\\ntargz_path = path(\\\"data/midi.tar.gz\\\")\\n\\ndot_list = [f\\\"tar_gz_path={targz_path}\\\", f\\\"outdir={tmp_path}\\\", \\\"partition_size=1\\\"]\\netl_cfg = OmegaConf.from_dotlist(dot_list)\\nflow = build_etl(etl_cfg)\\n\\ninit_stats()\\n\\nstarted_at = time.time()\\nflow.run()\\n\\ntest_eq(3, total_songs)\\ntest_eq(0, malformed_songs)\\ntest_eq(3, valid_songs)\\ntest_eq(1457, valid_notes)\\n\\ndf = fastparquet.ParquetFile(tmp_path, verify=True).to_pandas()\\npitches, durations, velocities = df.values[0]\\n\\ntest_eq([\\\"7.11.2\\\", \\\"7\\\", \\\"7\\\"], pitches[0:3])\\ntest_eq([1.75, 0.5, 0.5], durations[0:3])\\ntest_eq([110, 110, 110], velocities[0:3])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test\n",
    "from testing import test_eq, path\n",
    "from omegaconf import OmegaConf\n",
    "import fastparquet\n",
    "\n",
    "tmp_path = \"/tmp/neuralmusic_etl\"\n",
    "\n",
    "targz_path = path(\"data/midi.tar.gz\")\n",
    "\n",
    "dot_list = [f\"tar_gz_path={targz_path}\", f\"outdir={tmp_path}\", \"partition_size=1\"]\n",
    "etl_cfg = OmegaConf.from_dotlist(dot_list)\n",
    "flow = build_etl(etl_cfg)\n",
    "\n",
    "init_stats()\n",
    "\n",
    "started_at = time.time()\n",
    "flow.run()\n",
    "\n",
    "test_eq(3, total_songs)\n",
    "test_eq(0, malformed_songs)\n",
    "test_eq(3, valid_songs)\n",
    "test_eq(1457, valid_notes)\n",
    "\n",
    "df = fastparquet.ParquetFile(tmp_path, verify=True).to_pandas()\n",
    "pitches, durations, velocities = df.values[0]\n",
    "\n",
    "test_eq([\"7.11.2\", \"7\", \"7\"], pitches[0:3])\n",
    "test_eq([1.75, 0.5, 0.5], durations[0:3])\n",
    "test_eq([110, 110, 110], velocities[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
