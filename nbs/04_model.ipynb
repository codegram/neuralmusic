{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# hide\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# hide\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# default_exp model\";\n",
       "                var nbb_formatted_code = \"# default_exp model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default_exp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# export\\nimport torch\\nfrom torch import Tensor\\nimport torch.nn as nn\\nfrom fastai2.text.models import RNNDropout\";\n",
       "                var nbb_formatted_code = \"# export\\nimport torch\\nfrom torch import Tensor\\nimport torch.nn as nn\\nfrom fastai2.text.models import RNNDropout\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from fastai2.text.models import RNNDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "We're attempting to build a model that can effectively learn two parallel signals (pitch and duration) at the same time, with a single loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before, we'll take a piece from Fastai v1 that I couldn't find in Fastai2, the Linear Decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# export\\nclass LinearDecoder(nn.Module):\\n    initrange = 0.1\\n\\n    def __init__(\\n        self,\\n        n_out: int,\\n        n_hid: int,\\n        output_p: float,\\n        tie_encoder=None,\\n        bias: bool = True,\\n    ):\\n        super().__init__()\\n        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\\n        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\\n        self.output_dp = RNNDropout(output_p)\\n        if bias:\\n            self.decoder.bias.data.zero_()\\n        if tie_encoder:\\n            self.decoder.weight = tie_encoder.weight\\n\\n    def forward(self, input: Tensor) -> Tensor:\\n        output = self.output_dp(input)\\n        decoded = self.decoder(\\n            output.view(output.size(0) * output.size(1), output.size(2))\\n        )\\n        return decoded\";\n",
       "                var nbb_formatted_code = \"# export\\nclass LinearDecoder(nn.Module):\\n    initrange = 0.1\\n\\n    def __init__(\\n        self,\\n        n_out: int,\\n        n_hid: int,\\n        output_p: float,\\n        tie_encoder=None,\\n        bias: bool = True,\\n    ):\\n        super().__init__()\\n        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\\n        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\\n        self.output_dp = RNNDropout(output_p)\\n        if bias:\\n            self.decoder.bias.data.zero_()\\n        if tie_encoder:\\n            self.decoder.weight = tie_encoder.weight\\n\\n    def forward(self, input: Tensor) -> Tensor:\\n        output = self.output_dp(input)\\n        decoded = self.decoder(\\n            output.view(output.size(0) * output.size(1), output.size(2))\\n        )\\n        return decoded\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class LinearDecoder(nn.Module):\n",
    "    initrange = 0.1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_out: int,\n",
    "        n_hid: int,\n",
    "        output_p: float,\n",
    "        tie_encoder=None,\n",
    "        bias: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\n",
    "        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.output_dp = RNNDropout(output_p)\n",
    "        if bias:\n",
    "            self.decoder.bias.data.zero_()\n",
    "        if tie_encoder:\n",
    "            self.decoder.weight = tie_encoder.weight\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        output = self.output_dp(input)\n",
    "        decoded = self.decoder(\n",
    "            output.view(output.size(0) * output.size(1), output.size(2))\n",
    "        )\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# export\\nclass TheModel(nn.Module):\\n    def __init__(self, pitch_len, duration_len, emb_size=1000, rnn_size=1200, rnn_layers=3, dropout=0.0):\\n        super().__init__()\\n\\n        self.pitch_emb = nn.Embedding(num_embeddings=pitch_len, embedding_dim=emb_size, padding_idx=1)\\n        self.duration_emb = nn.Embedding(num_embeddings=duration_len, embedding_dim=emb_size, padding_idx=1)\\n\\n        self.hidden_size = rnn_size\\n        self.layers = rnn_layers\\n        self.pitch_rnn = nn.GRU(input_size=emb_size, hidden_size=rnn_size, num_layers=rnn_layers, batch_first=False, bidirectional=False)\\n        self.duration_rnn = nn.GRU(input_size=emb_size, hidden_size=rnn_size, num_layers=rnn_layers, batch_first=False, bidirectional=False)\\n\\n        self.pitch_dec = LinearDecoder(n_out=pitch_len, n_hid=rnn_size + rnn_size, output_p=dropout)\\n        self.duration_dec = LinearDecoder(n_out=duration_len, n_hid=rnn_size + rnn_size, output_p=dropout)\\n\\n        self.reset()\\n\\n    def forward(self, x):\\n        pitches, durations = x.transpose(0,1)\\n\\n        pitch_emb = self.pitch_emb(pitches).transpose(0,1)\\n        duration_emb = self.duration_emb(durations).transpose(0,1)\\n\\n        if self.pitch_hid is None:\\n          self.pitch_hid = self.init_hidden(self.layers, pitches.size(0), self.hidden_size)\\n        if self.duration_hid is None:\\n          self.duration_hid = self.init_hidden(self.layers, durations.size(0), self.hidden_size)\\n\\n        pitch, self.pitch_hid = self.pitch_rnn(pitch_emb, self.pitch_hid)\\n        duration, self.duration_hid = self.duration_rnn(duration_emb, self.duration_hid)\\n\\n        together = torch.cat([pitch, duration], dim=2)\\n\\n        pitch_decoded = self.pitch_dec(together)\\n        duration_decoded = self.duration_dec(together)\\n\\n        self.pitch_hid.detach_()\\n        self.duration_hid.detach_()\\n\\n        pitch_out = pitch_decoded.view(pitches.size(0), pitches.size(1), -1)\\n        duration_out = duration_decoded.view(durations.size(0), durations.size(1), -1)\\n\\n        return pitch_out, duration_out\\n\\n    def reset(self):\\n        self.pitch_hid = None\\n        self.duration_hid = None\\n\\n    def init_hidden(self, layers, batch_size, hidden_size):\\n        weight = next(self.parameters()).data\\n        return weight.new(layers, batch_size, hidden_size).zero_()\";\n",
       "                var nbb_formatted_code = \"# export\\nclass TheModel(nn.Module):\\n    def __init__(\\n        self,\\n        pitch_len,\\n        duration_len,\\n        emb_size=1000,\\n        rnn_size=1200,\\n        rnn_layers=3,\\n        dropout=0.0,\\n    ):\\n        super().__init__()\\n\\n        self.pitch_emb = nn.Embedding(\\n            num_embeddings=pitch_len, embedding_dim=emb_size, padding_idx=1\\n        )\\n        self.duration_emb = nn.Embedding(\\n            num_embeddings=duration_len, embedding_dim=emb_size, padding_idx=1\\n        )\\n\\n        self.hidden_size = rnn_size\\n        self.layers = rnn_layers\\n        self.pitch_rnn = nn.GRU(\\n            input_size=emb_size,\\n            hidden_size=rnn_size,\\n            num_layers=rnn_layers,\\n            batch_first=False,\\n            bidirectional=False,\\n        )\\n        self.duration_rnn = nn.GRU(\\n            input_size=emb_size,\\n            hidden_size=rnn_size,\\n            num_layers=rnn_layers,\\n            batch_first=False,\\n            bidirectional=False,\\n        )\\n\\n        self.pitch_dec = LinearDecoder(\\n            n_out=pitch_len, n_hid=rnn_size + rnn_size, output_p=dropout\\n        )\\n        self.duration_dec = LinearDecoder(\\n            n_out=duration_len, n_hid=rnn_size + rnn_size, output_p=dropout\\n        )\\n\\n        self.reset()\\n\\n    def forward(self, x):\\n        pitches, durations = x.transpose(0, 1)\\n\\n        pitch_emb = self.pitch_emb(pitches).transpose(0, 1)\\n        duration_emb = self.duration_emb(durations).transpose(0, 1)\\n\\n        if self.pitch_hid is None:\\n            self.pitch_hid = self.init_hidden(\\n                self.layers, pitches.size(0), self.hidden_size\\n            )\\n        if self.duration_hid is None:\\n            self.duration_hid = self.init_hidden(\\n                self.layers, durations.size(0), self.hidden_size\\n            )\\n\\n        pitch, self.pitch_hid = self.pitch_rnn(pitch_emb, self.pitch_hid)\\n        duration, self.duration_hid = self.duration_rnn(duration_emb, self.duration_hid)\\n\\n        together = torch.cat([pitch, duration], dim=2)\\n\\n        pitch_decoded = self.pitch_dec(together)\\n        duration_decoded = self.duration_dec(together)\\n\\n        self.pitch_hid.detach_()\\n        self.duration_hid.detach_()\\n\\n        pitch_out = pitch_decoded.view(pitches.size(0), pitches.size(1), -1)\\n        duration_out = duration_decoded.view(durations.size(0), durations.size(1), -1)\\n\\n        return pitch_out, duration_out\\n\\n    def reset(self):\\n        self.pitch_hid = None\\n        self.duration_hid = None\\n\\n    def init_hidden(self, layers, batch_size, hidden_size):\\n        weight = next(self.parameters()).data\\n        return weight.new(layers, batch_size, hidden_size).zero_()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class TheModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pitch_len,\n",
    "        duration_len,\n",
    "        emb_size=1000,\n",
    "        rnn_size=1200,\n",
    "        rnn_layers=3,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pitch_emb = nn.Embedding(\n",
    "            num_embeddings=pitch_len, embedding_dim=emb_size, padding_idx=1\n",
    "        )\n",
    "        self.duration_emb = nn.Embedding(\n",
    "            num_embeddings=duration_len, embedding_dim=emb_size, padding_idx=1\n",
    "        )\n",
    "\n",
    "        self.hidden_size = rnn_size\n",
    "        self.layers = rnn_layers\n",
    "        self.pitch_rnn = nn.GRU(\n",
    "            input_size=emb_size,\n",
    "            hidden_size=rnn_size,\n",
    "            num_layers=rnn_layers,\n",
    "            batch_first=False,\n",
    "            bidirectional=False,\n",
    "        )\n",
    "        self.duration_rnn = nn.GRU(\n",
    "            input_size=emb_size,\n",
    "            hidden_size=rnn_size,\n",
    "            num_layers=rnn_layers,\n",
    "            batch_first=False,\n",
    "            bidirectional=False,\n",
    "        )\n",
    "\n",
    "        self.pitch_dec = LinearDecoder(\n",
    "            n_out=pitch_len, n_hid=rnn_size + rnn_size, output_p=dropout\n",
    "        )\n",
    "        self.duration_dec = LinearDecoder(\n",
    "            n_out=duration_len, n_hid=rnn_size + rnn_size, output_p=dropout\n",
    "        )\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pitches, durations = x.transpose(0, 1)\n",
    "\n",
    "        pitch_emb = self.pitch_emb(pitches).transpose(0, 1)\n",
    "        duration_emb = self.duration_emb(durations).transpose(0, 1)\n",
    "\n",
    "        if self.pitch_hid is None:\n",
    "            self.pitch_hid = self.init_hidden(\n",
    "                self.layers, pitches.size(0), self.hidden_size\n",
    "            )\n",
    "        if self.duration_hid is None:\n",
    "            self.duration_hid = self.init_hidden(\n",
    "                self.layers, durations.size(0), self.hidden_size\n",
    "            )\n",
    "\n",
    "        pitch, self.pitch_hid = self.pitch_rnn(pitch_emb, self.pitch_hid)\n",
    "        duration, self.duration_hid = self.duration_rnn(duration_emb, self.duration_hid)\n",
    "\n",
    "        together = torch.cat([pitch, duration], dim=2)\n",
    "\n",
    "        pitch_decoded = self.pitch_dec(together)\n",
    "        duration_decoded = self.duration_dec(together)\n",
    "\n",
    "        self.pitch_hid.detach_()\n",
    "        self.duration_hid.detach_()\n",
    "\n",
    "        pitch_out = pitch_decoded.view(pitches.size(0), pitches.size(1), -1)\n",
    "        duration_out = duration_decoded.view(durations.size(0), durations.size(1), -1)\n",
    "\n",
    "        return pitch_out, duration_out\n",
    "\n",
    "    def reset(self):\n",
    "        self.pitch_hid = None\n",
    "        self.duration_hid = None\n",
    "\n",
    "    def init_hidden(self, layers, batch_size, hidden_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(layers, batch_size, hidden_size).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
